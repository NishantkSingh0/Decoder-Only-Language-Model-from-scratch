{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9248118,"sourceType":"datasetVersion","datasetId":5594660},{"sourceId":102384,"sourceType":"modelInstanceVersion","modelInstanceId":85844,"modelId":110074},{"sourceId":106697,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":89423,"modelId":113614}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2024-09-03T16:58:25.401742Z","iopub.execute_input":"2024-09-03T16:58:25.402026Z","iopub.status.idle":"2024-09-03T16:58:39.021155Z","shell.execute_reply.started":"2024-09-03T16:58:25.401988Z","shell.execute_reply":"2024-09-03T16:58:39.020234Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import mixed_precision\nimport sentencepiece as spm\nfrom tensorflow.keras.callbacks import EarlyStopping ,ModelCheckpoint\nimport os\nimport sys","metadata":{"execution":{"iopub.status.busy":"2024-09-03T16:58:39.023003Z","iopub.execute_input":"2024-09-03T16:58:39.023407Z","iopub.status.idle":"2024-09-03T16:58:51.119932Z","shell.execute_reply.started":"2024-09-03T16:58:39.023373Z","shell.execute_reply":"2024-09-03T16:58:51.118817Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"Data=pd.read_csv('/kaggle/input/refined-bookcorpus-dataset/BookCorpus3.csv',chunksize=50000,header=None)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T16:58:51.121238Z","iopub.execute_input":"2024-09-03T16:58:51.121909Z","iopub.status.idle":"2024-09-03T16:58:51.142490Z","shell.execute_reply.started":"2024-09-03T16:58:51.121865Z","shell.execute_reply":"2024-09-03T16:58:51.141405Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sp=spm.SentencePieceProcessor(r'/kaggle/input/bpemodel/transformers/default/1/Model/SPMsm.model')","metadata":{"execution":{"iopub.status.busy":"2024-09-03T16:58:51.145208Z","iopub.execute_input":"2024-09-03T16:58:51.145579Z","iopub.status.idle":"2024-09-03T16:58:51.191936Z","shell.execute_reply.started":"2024-09-03T16:58:51.145532Z","shell.execute_reply":"2024-09-03T16:58:51.191126Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def Numerical(Data,chunkSize):\n    Numeric=[]\n    for i,chunks in enumerate(Data):\n        if i>=chunkSize:\n            break\n        for para in chunks[0]:\n            enc=sp.encode(para)\n            length=len(enc)\n            if length>=100:\n                Numeric.append(enc[:100])\n    return np.array(Numeric)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-09-03T16:58:51.193168Z","iopub.execute_input":"2024-09-03T16:58:51.193499Z","iopub.status.idle":"2024-09-03T16:58:51.202592Z","shell.execute_reply.started":"2024-09-03T16:58:51.193467Z","shell.execute_reply":"2024-09-03T16:58:51.201755Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"FilteredData=Numerical(Data,20)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T16:58:51.204516Z","iopub.execute_input":"2024-09-03T16:58:51.204810Z","iopub.status.idle":"2024-09-03T17:03:35.575691Z","shell.execute_reply.started":"2024-09-03T16:58:51.204779Z","shell.execute_reply":"2024-09-03T17:03:35.574862Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n    filepath='/kaggle/working/Model_checkpoint.keras', \n    save_best_only=True, \n    monitor='val_loss', \n    mode='min'\n)\n\nearly_stopping_callback = EarlyStopping(\n    monitor='val_loss', \n    patience=2, \n    restore_best_weights=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:03:35.578605Z","iopub.execute_input":"2024-09-03T17:03:35.579283Z","iopub.status.idle":"2024-09-03T17:03:35.583829Z","shell.execute_reply.started":"2024-09-03T17:03:35.579238Z","shell.execute_reply":"2024-09-03T17:03:35.582963Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **Model Architecture**","metadata":{}},{"cell_type":"code","source":"class Attention(tf.keras.layers.Layer):\n  def __init__(self,num_heads,d_model,rate):\n    super(Attention,self).__init__()\n    self.num_heads=num_heads\n    self.d_model=d_model\n    assert d_model%num_heads==0,'d model must divisible by number of heads'\n    self.depth=d_model//num_heads\n    self.K=tf.keras.layers.Dense(d_model)\n    self.Q=tf.keras.layers.Dense(d_model)\n    self.V=tf.keras.layers.Dense(d_model)\n    self.norm=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n    self.dropout=tf.keras.layers.Dropout(rate)\n  \n  def build(self, input_shape):\n        # No additional weights to add in this example, but here's where they would be added.\n    pass\n\n  def AttentionScore(self,K,Q,V,mask=None):\n    kq=tf.matmul(Q,K,transpose_b=True)      # (12, 4, 299, 299)\n    dk=tf.math.sqrt(tf.cast(self.d_model,tf.float16))\n    # print(kq.shape)\n    if mask is not None:\n        mask=tf.cast(mask,tf.float16)\n        dk+=mask*-1e9\n    softmax=tf.nn.softmax(kq/dk,axis=-1)\n    output=tf.matmul(softmax,V)\n    return output,softmax\n\n  def SplitHeads(self,X,batch_size):\n    X=tf.reshape(X,(batch_size,-1,self.num_heads,self.depth))\n    return tf.transpose(X,(0,2,1,3))\n\n  def call(self,K,Q,V,mask,training):\n    batch_size=tf.shape(Q)[0]\n    Ke=self.K(K)           # (batch_size, seq_len, d_model)\n    Qu=self.Q(Q)\n    Va=self.V(V)\n    k=self.SplitHeads(Ke,batch_size)           # (batch_size, num_heads, seq_len, depth)  ->  (12, 4, 299, 25)\n    q=self.SplitHeads(Qu,batch_size)\n    v=self.SplitHeads(Va,batch_size)\n    # print(k.shape)\n    output,attention_weights=self.AttentionScore(k,q,v,mask)\n    output=tf.transpose(output,(0,2,1,3))\n    output=tf.reshape(output,(batch_size,-1,self.d_model))\n    output=self.dropout(output,training=training)\n    output=self.norm(output+Q)\n    return output,attention_weights","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:09:51.023205Z","iopub.execute_input":"2024-09-03T17:09:51.023956Z","iopub.status.idle":"2024-09-03T17:09:51.037529Z","shell.execute_reply.started":"2024-09-03T17:09:51.023916Z","shell.execute_reply":"2024-09-03T17:09:51.036523Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class PointwiseFNN(tf.keras.layers.Layer):\n  def __init__(self,dff,d_model,rate):\n    super(PointwiseFNN,self).__init__()\n    self.d_model=d_model\n    self.dff=dff\n    self.dense1=tf.keras.layers.Dense(dff,activation='relu')\n    self.dense2=tf.keras.layers.Dense(d_model)\n    self.dropout=tf.keras.layers.Dropout(rate)\n    self.norm=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n    \n  def build(self, input_shape):\n        # No additional weights to add in this example, but here's where they would be added.\n    pass\n\n  def call(self,X,training):\n    out=self.dense1(X)\n    out=self.dense2(out)\n    out=self.dropout(out,training=training)\n    out=self.norm(out+X)\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:09:57.637374Z","iopub.execute_input":"2024-09-03T17:09:57.637993Z","iopub.status.idle":"2024-09-03T17:09:57.646053Z","shell.execute_reply.started":"2024-09-03T17:09:57.637953Z","shell.execute_reply":"2024-09-03T17:09:57.644957Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(tf.keras.layers.Layer):\n  def __init__(self,d_model,num_heads,dff,rate):\n    super(DecoderLayer,self).__init__()\n    self.mha1=Attention(num_heads,d_model,rate)\n    self.ffn=PointwiseFNN(dff,d_model,rate)\n    \n  def build(self, input_shape):\n        # No additional weights to add in this example, but here's where they would be added.\n     pass\n\n  def call(self,X,mask,training):\n    out,attentionWeights=self.mha1(X,X,X,mask=mask,training=training)\n    out=self.ffn(out,training=training)\n    return out,attentionWeights","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:09:58.027017Z","iopub.execute_input":"2024-09-03T17:09:58.027910Z","iopub.status.idle":"2024-09-03T17:09:58.034535Z","shell.execute_reply.started":"2024-09-03T17:09:58.027871Z","shell.execute_reply":"2024-09-03T17:09:58.033472Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n    def __init__(self,dff,d_model,num_heads,vocab_size,numLayers,seq_len,rate):\n        super(Decoder,self).__init__()\n        self.d_model=d_model\n        self.numLayers=numLayers\n        self.Embedding=tf.keras.layers.Embedding(vocab_size,d_model)\n        self.Layers=[DecoderLayer(d_model,num_heads,dff,rate) for i in range(numLayers)]\n        self.PE=self.PEncoding(d_model,seq_len)\n        self.dropout=tf.keras.layers.Dropout(rate)\n        self.norm=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.dense1=tf.keras.layers.Dense(d_model,activation='relu')\n        self.dense2=tf.keras.layers.Dense(vocab_size,activation='softmax')\n    \n    def build(self, input_shape):\n        # No additional weights to add in this example, but here's where they would be added.\n        pass\n\n    def PEncoding(self,d_model,seq_len):\n        angles=self.GetAngle(np.arange(seq_len)[:,np.newaxis],np.arange(d_model)[np.newaxis,:],d_model)\n        angles[:,0::2]=np.sin(angles[:,0::2])\n        angles[:,1::2]=np.cos(angles[:,1::2])\n        angles=angles[np.newaxis,...]\n        return tf.cast(angles,tf.float16)\n\n    def GetAngle(self,pos,i,d_model):\n        A=1/np.power(10000,2*(i//2)/np.float16(d_model))\n        return pos*A\n    # def call(self,Deinputs,Enoutput,decPadMask,DecLAM,training):\n    # pred, weights = LLM(para, mask, training=True)\n    def call(self,inputs,mask,training=False):\n        seq_len=tf.shape(inputs)[1]\n        X=self.Embedding(inputs)\n        X*=tf.math.sqrt(tf.cast(self.d_model,tf.float16))\n        X+=self.PE[:,seq_len:,:]\n        X=self.dropout(X,training=training)\n        Decweights={}\n        for i in range(self.numLayers):\n            X,soft=self.Layers[i](X,mask=mask,training=training)\n            Decweights[f'Decoder layer{i+1}']=soft\n        X=self.dense1(X)\n        X=self.dense2(X)\n        return X,Decweights","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:09:58.412311Z","iopub.execute_input":"2024-09-03T17:09:58.413035Z","iopub.status.idle":"2024-09-03T17:09:58.426494Z","shell.execute_reply.started":"2024-09-03T17:09:58.412998Z","shell.execute_reply":"2024-09-03T17:09:58.425537Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def Mask(Element):\n    size = tf.shape(Element)[1]\n    padMask = tf.cast(tf.equal(Element, 0), tf.float16)\n    padMask = padMask[:, tf.newaxis, :]  # Shape: (num_paragraphs, 1, 300)\n\n    LAMask = 1 - tf.cast(tf.linalg.band_part(tf.ones((size, size)), -1, 0),tf.float16)\n    LAMask = LAMask[tf.newaxis, :, :]  # Shape: (1, 300, 300)\n\n    combined_mask = tf.maximum(padMask, LAMask)  # Shape: (num_paragraphs, 300, 300)\n\n    return combined_mask[:,tf.newaxis,:,:]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:09:58.717513Z","iopub.execute_input":"2024-09-03T17:09:58.718612Z","iopub.status.idle":"2024-09-03T17:09:58.725226Z","shell.execute_reply.started":"2024-09-03T17:09:58.718560Z","shell.execute_reply":"2024-09-03T17:09:58.724255Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# **Defining WarmupSchedule**","metadata":{}},{"cell_type":"code","source":"class WarmupLearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_lr, warmup_steps, total_steps):\n        self.initial_lr = initial_lr\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n\n    def __call__(self, step):\n        step = tf.cast(step, dtype=tf.float32)\n        warmup_steps = tf.cast(self.warmup_steps, dtype=tf.float32)\n        total_steps = tf.cast(self.total_steps, dtype=tf.float32)\n\n        def warmup_lr():\n            return self.initial_lr * (step / warmup_steps)\n\n        def decay_lr():\n            return self.initial_lr * tf.math.exp(-0.1 * (step - warmup_steps) / (total_steps - warmup_steps))\n\n        return tf.cond(step < warmup_steps,\n                       true_fn=warmup_lr,\n                       false_fn=decay_lr)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:09:59.507229Z","iopub.execute_input":"2024-09-03T17:09:59.508094Z","iopub.status.idle":"2024-09-03T17:09:59.515366Z","shell.execute_reply.started":"2024-09-03T17:09:59.508055Z","shell.execute_reply":"2024-09-03T17:09:59.514449Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# **Hyperparameters Adjustment**","metadata":{}},{"cell_type":"code","source":"dff=512\nd_model=204\nnum_heads=6\nvocab_size=20001\nnumLayers=8\nseq_len=100\nrate=0.3\nBUFFER_SIZE=len(FilteredData)\nBATCH_SIZE=64","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:10:00.262036Z","iopub.execute_input":"2024-09-03T17:10:00.262937Z","iopub.status.idle":"2024-09-03T17:10:00.267568Z","shell.execute_reply.started":"2024-09-03T17:10:00.262894Z","shell.execute_reply":"2024-09-03T17:10:00.266638Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# **Managing Dataset for Training**","metadata":{}},{"cell_type":"code","source":"# Mixed precision policy (Optional: TPUs often benefit from float16)\n\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:10:00.912016Z","iopub.execute_input":"2024-09-03T17:10:00.912736Z","iopub.status.idle":"2024-09-03T17:10:00.916883Z","shell.execute_reply.started":"2024-09-03T17:10:00.912689Z","shell.execute_reply":"2024-09-03T17:10:00.915951Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"target=tf.cast(tf.constant(FilteredData[:, 1:]),tf.float16)\nPara=tf.cast(tf.constant(FilteredData[:,:-1]),tf.float16)\nDataset=tf.data.Dataset.from_tensor_slices((Para,target))\nDataset=Dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True).prefetch(tf.data.AUTOTUNE).cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:10:02.506950Z","iopub.execute_input":"2024-09-03T17:10:02.507610Z","iopub.status.idle":"2024-09-03T17:10:03.971216Z","shell.execute_reply.started":"2024-09-03T17:10:02.507570Z","shell.execute_reply":"2024-09-03T17:10:03.970390Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# **Custom Training**","metadata":{}},{"cell_type":"code","source":"learning_rate = WarmupLearningRateSchedule(initial_lr=3e-4, warmup_steps=500, total_steps=len(FilteredData)//BATCH_SIZE)\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\naccuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\nLLM = Decoder(dff, d_model, num_heads, vocab_size, numLayers, seq_len, rate)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:10:05.357173Z","iopub.execute_input":"2024-09-03T17:10:05.357875Z","iopub.status.idle":"2024-09-03T17:10:05.508205Z","shell.execute_reply.started":"2024-09-03T17:10:05.357834Z","shell.execute_reply":"2024-09-03T17:10:05.507439Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback.set_model(LLM)\nearly_stopping_callback.set_model(LLM)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:10:05.931867Z","iopub.execute_input":"2024-09-03T17:10:05.932298Z","iopub.status.idle":"2024-09-03T17:10:05.936905Z","shell.execute_reply.started":"2024-09-03T17:10:05.932256Z","shell.execute_reply":"2024-09-03T17:10:05.935790Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(para, target):\n    mask = Mask(para)\n    with tf.GradientTape() as tape:\n        pred, weights = LLM(para, mask, training=True)\n        loss = loss_object(target, pred)\n    gradients = tape.gradient(loss, LLM.trainable_variables)\n    gradients = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gradients]\n    optimizer.apply_gradients(zip(gradients, LLM.trainable_variables))\n    accuracy.update_state(target, pred)\n    return loss\n\nEPOCHS = 15\nbest_val_loss = float('inf')\n\n# Custom training loop\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n    for step, (para, target) in enumerate(Dataset):\n        loss = train_step(para, target)\n    print(f\"Loss: {loss.numpy()}, Accuracy: {accuracy.result().numpy()}\")\n    accuracy.reset_state()\n    checkpoint_callback.on_epoch_end(epoch, logs={'val_loss': loss.numpy()})\n    early_stopping_callback.on_epoch_end(epoch, logs={'val_loss': loss.numpy()})\n\n    if early_stopping_callback.stopped_epoch > 0:\n        print(\"Early stopping triggered.\")\n        break\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:10:06.827196Z","iopub.execute_input":"2024-09-03T17:10:06.827594Z","iopub.status.idle":"2024-09-03T17:43:40.790956Z","shell.execute_reply.started":"2024-09-03T17:10:06.827556Z","shell.execute_reply":"2024-09-03T17:43:40.790029Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py:522: RuntimeWarning: overflow encountered in cast\n  nparray = np.array(values, dtype=np_dt)\n","output_type":"stream"},{"name":"stdout","text":"Loss: nan, Accuracy: 0.002800866262987256\nEpoch 2/15\nLoss: nan, Accuracy: 0.002800866262987256\nEarly stopping triggered.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install kaggle\nkaggle datasets create -p /kaggle/working/ -t \"Model Outputs\"","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:43:40.792803Z","iopub.execute_input":"2024-09-03T17:43:40.793144Z","iopub.status.idle":"2024-09-03T17:43:40.799884Z","shell.execute_reply.started":"2024-09-03T17:43:40.793086Z","shell.execute_reply":"2024-09-03T17:43:40.798719Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[21], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    kaggle datasets create -p /kaggle/working/ -t \"Model Outputs\"\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (978890898.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"print('Done!')","metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:43:40.801058Z","iopub.status.idle":"2024-09-03T17:43:40.801861Z","shell.execute_reply.started":"2024-09-03T17:43:40.801626Z","shell.execute_reply":"2024-09-03T17:43:40.801647Z"},"trusted":true},"execution_count":null,"outputs":[]}]}