{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9248118,"sourceType":"datasetVersion","datasetId":5594660},{"sourceId":102384,"sourceType":"modelInstanceVersion","modelInstanceId":85844,"modelId":110074},{"sourceId":106697,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":89423,"modelId":113614}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2024-09-04T16:47:03.357367Z","iopub.execute_input":"2024-09-04T16:47:03.357857Z","iopub.status.idle":"2024-09-04T16:47:21.149947Z","shell.execute_reply.started":"2024-09-04T16:47:03.357811Z","shell.execute_reply":"2024-09-04T16:47:21.148109Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import mixed_precision\nimport sentencepiece as spm\nimport os\nimport sys","metadata":{"execution":{"iopub.status.busy":"2024-09-04T16:47:21.153137Z","iopub.execute_input":"2024-09-04T16:47:21.153627Z","iopub.status.idle":"2024-09-04T16:47:37.858476Z","shell.execute_reply.started":"2024-09-04T16:47:21.153567Z","shell.execute_reply":"2024-09-04T16:47:37.857169Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"Data=pd.read_csv('/kaggle/input/refined-bookcorpus-dataset/BookCorpus3.csv',chunksize=50000,header=None)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:04:06.206173Z","iopub.execute_input":"2024-09-04T17:04:06.206659Z","iopub.status.idle":"2024-09-04T17:04:06.248403Z","shell.execute_reply.started":"2024-09-04T17:04:06.206612Z","shell.execute_reply":"2024-09-04T17:04:06.247089Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"chunk1=next(Data)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:04:41.352265Z","iopub.execute_input":"2024-09-04T17:04:41.352765Z","iopub.status.idle":"2024-09-04T17:04:41.926965Z","shell.execute_reply.started":"2024-09-04T17:04:41.352710Z","shell.execute_reply":"2024-09-04T17:04:41.925595Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"chunk1[0][25]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:05:38.396708Z","iopub.execute_input":"2024-09-04T17:05:38.397162Z","iopub.status.idle":"2024-09-04T17:05:38.405090Z","shell.execute_reply.started":"2024-09-04T17:05:38.397118Z","shell.execute_reply":"2024-09-04T17:05:38.403800Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"\"a third person would mean an opportunity to come together with her and with konnor to help keep them all alive. that is, if konnor didn't go completely over the deep end. she would have to take time to better assess his condition. even as she considered doing that, she knew she would have problems.\""},"metadata":{}}]},{"cell_type":"code","source":"sp=spm.SentencePieceProcessor(r'/kaggle/input/bpemodel/transformers/default/1/Model/SPMsm.model')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:24:53.829566Z","iopub.execute_input":"2024-09-04T13:24:53.829944Z","iopub.status.idle":"2024-09-04T13:24:53.876818Z","shell.execute_reply.started":"2024-09-04T13:24:53.829897Z","shell.execute_reply":"2024-09-04T13:24:53.875979Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def Numerical(Data,chunkSize):\n    Numeric=[]\n    for i,chunks in enumerate(Data):\n        if i>=chunkSize:\n            break\n        for para in chunks[0]:\n            enc=sp.encode(para)\n            length=len(enc)\n            if length>=100:\n                Numeric.append(enc[:100])\n    return np.array(Numeric)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:24:53.877981Z","iopub.execute_input":"2024-09-04T13:24:53.878349Z","iopub.status.idle":"2024-09-04T13:24:53.887358Z","shell.execute_reply.started":"2024-09-04T13:24:53.878316Z","shell.execute_reply":"2024-09-04T13:24:53.886458Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"FilteredData=Numerical(Data,20)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:24:53.888595Z","iopub.execute_input":"2024-09-04T13:24:53.888868Z","iopub.status.idle":"2024-09-04T13:29:38.640942Z","shell.execute_reply.started":"2024-09-04T13:24:53.888837Z","shell.execute_reply":"2024-09-04T13:29:38.640099Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **Model Architecture**","metadata":{}},{"cell_type":"code","source":"class Attention(tf.keras.layers.Layer):\n  def __init__(self,num_heads,d_model,rate):\n    super(Attention,self).__init__()\n    self.num_heads=num_heads\n    self.d_model=d_model\n    assert d_model%num_heads==0,'d model must divisible by number of heads'\n    self.depth=d_model//num_heads\n    self.K=tf.keras.layers.Dense(d_model)\n    self.Q=tf.keras.layers.Dense(d_model)\n    self.V=tf.keras.layers.Dense(d_model)\n    self.norm=tf.keras.layers.LayerNormalization(epsilon=1e-5)\n    self.dropout=tf.keras.layers.Dropout(rate)\n\n  def build(self, input_shape):\n        # No additional weights to add in this example, but here's where they would be added.\n    pass\n\n  def AttentionScore(self,K,Q,V,mask=None):\n    kq=tf.matmul(Q,K,transpose_b=True)      # (12, 4, 299, 299)\n    dk=tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n    # print(kq.shape)\n    if mask is not None:\n        mask=tf.cast(mask,tf.float32)\n        kq+=mask*-1e9\n    softmax=tf.nn.softmax(kq/dk,axis=-1)\n    output=tf.matmul(softmax,V)\n    return output,softmax\n\n  def SplitHeads(self,X,batch_size):\n    X=tf.reshape(X,(batch_size,-1,self.num_heads,self.depth))\n    return tf.transpose(X,(0,2,1,3))\n\n  def call(self,K,Q,V,mask,training):\n    batch_size=tf.shape(Q)[0]\n    Ke=self.K(K)           # (batch_size, seq_len, d_model)\n    Qu=self.Q(Q)\n    Va=self.V(V)\n    k=self.SplitHeads(Ke,batch_size)           # (batch_size, num_heads, seq_len, depth)  ->  (12, 4, 299, 25)\n    q=self.SplitHeads(Qu,batch_size)\n    v=self.SplitHeads(Va,batch_size)\n    # print(k.shape)\n    output,attention_weights=self.AttentionScore(k,q,v,mask)\n    output=tf.transpose(output,(0,2,1,3))\n    output=tf.reshape(output,(batch_size,-1,self.d_model))\n    output=self.dropout(output,training=training)\n    output=self.norm(output+Q)\n    return output,attention_weights","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.642157Z","iopub.execute_input":"2024-09-04T13:29:38.642565Z","iopub.status.idle":"2024-09-04T13:29:38.656705Z","shell.execute_reply.started":"2024-09-04T13:29:38.642523Z","shell.execute_reply":"2024-09-04T13:29:38.655771Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class PointwiseFNN(tf.keras.layers.Layer):\n  def __init__(self,dff,d_model,rate):\n    super(PointwiseFNN,self).__init__()\n    self.d_model=d_model\n    self.dff=dff\n    self.dense1=tf.keras.layers.Dense(dff,activation='relu')\n    self.dense2=tf.keras.layers.Dense(d_model)\n    self.dropout=tf.keras.layers.Dropout(rate)\n    self.norm=tf.keras.layers.LayerNormalization(epsilon=1e-5)\n    \n  def build(self, input_shape):\n        # No additional weights to add in this example, but here's where they would be added.\n    pass\n\n  def call(self,X,training):\n    out=self.dense1(X)\n    out=self.dense2(out)\n    out=self.dropout(out,training=training)\n    out=self.norm(out+X)\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.657809Z","iopub.execute_input":"2024-09-04T13:29:38.658084Z","iopub.status.idle":"2024-09-04T13:29:38.671521Z","shell.execute_reply.started":"2024-09-04T13:29:38.658054Z","shell.execute_reply":"2024-09-04T13:29:38.670731Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(tf.keras.layers.Layer):\n  def __init__(self,d_model,num_heads,dff,rate):\n    super(DecoderLayer,self).__init__()\n    self.mha1=Attention(num_heads,d_model,rate)\n    self.ffn=PointwiseFNN(dff,d_model,rate)\n    \n  def build(self, input_shape):\n        # No additional weights to add in this example, but here's where they would be added.\n     pass\n\n  def call(self,X,mask,training):\n    out,attentionWeights=self.mha1(X,X,X,mask=mask,training=training)\n    out=self.ffn(out,training=training)\n    return out,attentionWeights","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.672414Z","iopub.execute_input":"2024-09-04T13:29:38.672697Z","iopub.status.idle":"2024-09-04T13:29:38.683953Z","shell.execute_reply.started":"2024-09-04T13:29:38.672667Z","shell.execute_reply":"2024-09-04T13:29:38.683132Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n    def __init__(self,dff,d_model,num_heads,vocab_size,numLayers,seq_len,rate):\n        super(Decoder,self).__init__()\n        self.d_model=d_model\n        self.numLayers=numLayers\n        self.Embedding=tf.keras.layers.Embedding(vocab_size,d_model)\n        self.Layers=[DecoderLayer(d_model,num_heads,dff,rate) for i in range(numLayers)]\n        self.PE=self.PEncoding(d_model,seq_len)\n        self.dropout=tf.keras.layers.Dropout(rate)\n        self.norm=tf.keras.layers.LayerNormalization(epsilon=1e-5)\n        self.dense1=tf.keras.layers.Dense(d_model,activation='relu')\n        self.dense2=tf.keras.layers.Dense(vocab_size)\n    \n    def build(self, input_shape):\n        # No additional weights to add in this example, but here's where they would be added.\n        pass\n\n    def PEncoding(self,d_model,seq_len):\n        angles=self.GetAngle(np.arange(seq_len)[:,np.newaxis],np.arange(d_model)[np.newaxis,:],d_model)\n        angles[:,0::2]=np.sin(angles[:,0::2])\n        angles[:,1::2]=np.cos(angles[:,1::2])\n        angles=angles[np.newaxis,...]\n        return tf.cast(angles,tf.float32)\n\n    def GetAngle(self,pos,i,d_model):\n        A=1/np.power(10000,2*(i//2)/np.float32(d_model))\n        return pos*A\n    # def call(self,Deinputs,Enoutput,decPadMask,DecLAM,training):\n    # pred, weights = LLM(para, mask, training=True)\n    def call(self,inputs,mask,training=False):\n        seq_len=tf.shape(inputs)[1]\n        X=self.Embedding(inputs)\n        X*=tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n        X+=self.PE[:,seq_len:,:]\n        Decweights={}\n        for i in range(self.numLayers):\n            X,soft=self.Layers[i](X,mask=mask,training=training)\n            Decweights[f'Decoder layer{i+1}']=soft\n        X=self.dense1(X)\n        X=self.dropout(X,training=training)\n        X=self.dense2(X)\n        return X,Decweights","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.686888Z","iopub.execute_input":"2024-09-04T13:29:38.687270Z","iopub.status.idle":"2024-09-04T13:29:38.700967Z","shell.execute_reply.started":"2024-09-04T13:29:38.687235Z","shell.execute_reply":"2024-09-04T13:29:38.700029Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **Defining WarmupSchedule**","metadata":{}},{"cell_type":"code","source":"class WarmupLearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_lr, warmup_steps, total_steps):\n        self.initial_lr = initial_lr\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n\n    def __call__(self, step):\n        step = tf.cast(step, dtype=tf.float32)\n        warmup_steps = tf.cast(self.warmup_steps, dtype=tf.float32)\n        total_steps = tf.cast(self.total_steps, dtype=tf.float32)\n\n        def warmup_lr():\n            return self.initial_lr * (step / warmup_steps)\n\n        def decay_lr():\n            return self.initial_lr * tf.math.exp(-0.1 * (step - warmup_steps) / (total_steps - warmup_steps))\n\n        return tf.cond(step < warmup_steps,\n                       true_fn=warmup_lr,\n                       false_fn=decay_lr)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.702156Z","iopub.execute_input":"2024-09-04T13:29:38.702803Z","iopub.status.idle":"2024-09-04T13:29:38.713468Z","shell.execute_reply.started":"2024-09-04T13:29:38.702761Z","shell.execute_reply":"2024-09-04T13:29:38.712636Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# **Hyperparameters Adjustment**","metadata":{}},{"cell_type":"code","source":"dff=512\nd_model=204\nnum_heads=6\nvocab_size=sp.get_piece_size()+1\nnumLayers=8\nseq_len=100\nrate=0.3\nBUFFER_SIZE=len(FilteredData)\nBATCH_SIZE=64","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.714963Z","iopub.execute_input":"2024-09-04T13:29:38.715265Z","iopub.status.idle":"2024-09-04T13:29:38.726473Z","shell.execute_reply.started":"2024-09-04T13:29:38.715222Z","shell.execute_reply":"2024-09-04T13:29:38.725632Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **Managing Dataset for Training**","metadata":{}},{"cell_type":"code","source":"def Mask(Element):\n    size = tf.shape(Element)[1]\n    padMask = tf.cast(tf.equal(Element, 0), tf.float32)\n    padMask = padMask[:, tf.newaxis, :]  # Shape: (num_paragraphs, 1, 300)\n\n    LAMask = 1 - tf.cast(tf.linalg.band_part(tf.ones((size, size)), -1, 0),tf.float32)\n    LAMask = LAMask[tf.newaxis, :, :]  # Shape: (1, 300, 300)\n\n    combined_mask = tf.maximum(padMask, LAMask)  # Shape: (num_paragraphs, 300, 300)\n\n    return combined_mask[:,tf.newaxis,:,:]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.727471Z","iopub.execute_input":"2024-09-04T13:29:38.727821Z","iopub.status.idle":"2024-09-04T13:29:38.736373Z","shell.execute_reply.started":"2024-09-04T13:29:38.727779Z","shell.execute_reply":"2024-09-04T13:29:38.735662Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# policy = mixed_precision.Policy('mixed_float32')\n# mixed_precision.set_global_policy(policy)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.737324Z","iopub.execute_input":"2024-09-04T13:29:38.737833Z","iopub.status.idle":"2024-09-04T13:29:38.744958Z","shell.execute_reply.started":"2024-09-04T13:29:38.737802Z","shell.execute_reply":"2024-09-04T13:29:38.744106Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"target=tf.cast(tf.constant(FilteredData[:, 1:]),tf.float32)\nPara=tf.cast(tf.constant(FilteredData[:,:-1]),tf.float32)\nDataset=tf.data.Dataset.from_tensor_slices((Para,target))\nDataset=Dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True).prefetch(tf.data.AUTOTUNE).cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:38.746213Z","iopub.execute_input":"2024-09-04T13:29:38.746831Z","iopub.status.idle":"2024-09-04T13:29:40.273146Z","shell.execute_reply.started":"2024-09-04T13:29:38.746789Z","shell.execute_reply":"2024-09-04T13:29:40.272352Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# **Custom Training**","metadata":{}},{"cell_type":"code","source":"learning_rate = WarmupLearningRateSchedule(initial_lr=8e-5, warmup_steps=500, total_steps=len(FilteredData)//BATCH_SIZE)\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\naccuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nLLM = Decoder(dff, d_model, num_heads, vocab_size, numLayers, seq_len, rate)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:40.274277Z","iopub.execute_input":"2024-09-04T13:29:40.274599Z","iopub.status.idle":"2024-09-04T13:29:40.426437Z","shell.execute_reply.started":"2024-09-04T13:29:40.274564Z","shell.execute_reply":"2024-09-04T13:29:40.425639Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(para, target):\n    mask = Mask(para)\n    with tf.GradientTape() as tape:\n        pred, weights = LLM(para, mask, training=True)\n        loss = loss_object(target, pred)\n    gradients = tape.gradient(loss, LLM.trainable_variables)\n    gradients = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gradients]\n    optimizer.apply_gradients(zip(gradients, LLM.trainable_variables))\n    accuracy.update_state(target, pred)\n    return loss\n\nEPOCHS = 15\n\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n    for step, (para, target) in enumerate(Dataset):\n        loss = train_step(para, target)\n        if step%1500==0:\n            print(f\"Batch:{step} | Loss: {loss.numpy()} | Accuracy: {accuracy.result().numpy()}\")\n    print(f\"Loss: {loss.numpy()} | Accuracy: {accuracy.result().numpy()}\\n\")\n    LLM.save(fr'/kaggle/working/NiftyEpoch{epoch}_{np.round(loss.numpy(),3)}_{np.round(accuracy.result().numpy()*100,2)}.keras')\n    LLM.save(fr'/kaggle/working/NiftyEpoch{epoch}_{np.round(loss.numpy(),3)}_{np.round(accuracy.result().numpy()*100,2)}.h5')\n    accuracy.reset_state()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LLM(FilteredData[1:2][:,:-1],Mask(FilteredData[1:2][:,:-1]),training=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LLM.save(r'/kaggle/working/Nifty.keras')\nLLM.save(r'/kaggle/working/Nifty.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}